{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a cybersecurity expert specializing in neural-symbolic defense systems for network intrusion detection. I need your assistance to adapt the symbolic component of our trained Transformer in reinforcement learning defense agent to enhance its performance in a new deployment environment.\n",
    "\n",
    "## BACKGROUND AND PROBLEM FORMULATION\n",
    "\n",
    "Our research involves a neural-symbolic defense agent for Network Intrusion Detection Systems (NIDS) focused on Distributed Denial of Service (DDoS) attacks. The agent architecture combines:\n",
    "1. A neural component (RL agent) that processes network observations and selects actions\n",
    "2. A symbolic component (rule-based program) that executes concrete defense operations based on the RL agent's action selection\n",
    "\n",
    "While the agent performs optimally in its training environment, we observe significant performance degradation when deploying it in larger-scale environments. Rather than retraining the neural component (which would require substantial data collection, training time, and safety verification), we aim to adapt only the symbolic program component.\n",
    "\n",
    "## ENVIRONMENT SPECIFICATIONS\n",
    "\n",
    "### Current Simulator: NS3\n",
    "\n",
    "### Training Environment Parameters:\n",
    "- Attack agents (botnet nodes): {TRAIN_ATTACK_AGENTS_MIN}-{TRAIN_ATTACK_AGENTS_MAX}\n",
    "- Legitimate clients: {TRAIN_LEGITIMATE_CLIENTS_MIN}-{TRAIN_LEGITIMATE_CLIENTS_MAX} \n",
    "- Servers/workstations in victim LAN: {TRAIN_SERVERS_MIN}-{TRAIN_SERVERS_MAX}\n",
    "- Legitimate transmissions: {TRAIN_TRANSMISSIONS_MIN}-{TRAIN_TRANSMISSIONS_MAX}\n",
    "\n",
    "### Deployment Environment Parameters:\n",
    "- Attack agents (botnet nodes): {DEPLOY_ATTACK_AGENTS_MIN}-{DEPLOY_ATTACK_AGENTS_MAX} ({ATTACK_AGENTS_INCREASE_PERCENT}% increase)\n",
    "- Legitimate clients: {DEPLOY_LEGITIMATE_CLIENTS_MIN}-{DEPLOY_LEGITIMATE_CLIENTS_MAX} ({LEGITIMATE_CLIENTS_INCREASE_PERCENT}% increase)\n",
    "- Servers/workstations in victim LAN: {DEPLOY_SERVERS_MIN}-{DEPLOY_SERVERS_MAX} ({SERVERS_INCREASE_PERCENT}% increase)\n",
    "- Legitimate transmissions: {DEPLOY_TRANSMISSIONS_MIN}-{DEPLOY_TRANSMISSIONS_MAX} ({TRANSMISSIONS_INCREASE_PERCENT}% increase)\n",
    "\n",
    "## CURRENT SYMBOLIC PROGRAM\n",
    "\n",
    "The neural component selects from four discrete actions {{a₀, a₁, a₂, a₃}}, with the following symbolic program implementation:\n",
    "\n",
    "```C++\n",
    "{CURRENT_SYMBOLIC_PROGRAM}\n",
    "```\n",
    "\n",
    "## PERFORMANCE METRICS AND DEGRADATION\n",
    "\n",
    "We observe the following performance degradation as attack intensity increases in the deployment environment:\n",
    "\n",
    "{PERFORMANCE_METRICS_TABLE}\n",
    "\n",
    "The critical issues identified:\n",
    "1. {ISSUE_1}\n",
    "2. {ISSUE_2}\n",
    "3. {ISSUE_3}\n",
    "4. {ISSUE_4}\n",
    "\n",
    "## YOUR TASK\n",
    "\n",
    "Please propose specific modifications to our symbolic program to enhance its performance in the larger-scale deployment environment. Your recommendations should:\n",
    "\n",
    "1. Maintain the overall interface with the neural component (four discrete actions)\n",
    "2. Adapt the symbolic program's parameters, thresholds, and internal logic to handle significantly larger numbers of legitimate and malicious nodes\n",
    "3. Address the identified bottlenecks in suspicious list management (especially for action a₂)\n",
    "4. Reduce false positive rates while maintaining effective defense capabilities\n",
    "5. Improve dynamic adjustment to varying network environment\n",
    "\n",
    "For each proposed modification, please:\n",
    "- Specify the exact code changes\n",
    "- Explain the theoretical justification\n",
    "- Discuss anticipated improvements in each performance metric\n",
    "- Address potential trade-offs or limitations\n",
    "\n",
    "Your guidance will directly inform our research on LLM-guided adaptation of symbolic programs for neural-symbolic cybersecurity agents.\n",
    "\"\"\"\n",
    "\n",
    "# Example usage with sample values\n",
    "def format_prompt(\n",
    "    # Training environment parameters\n",
    "    train_attack_agents_min=5,\n",
    "    train_attack_agents_max=10,\n",
    "    train_legitimate_clients_min=15,\n",
    "    train_legitimate_clients_max=30,\n",
    "    train_servers_min=0,\n",
    "    train_servers_max=10,\n",
    "    train_transmissions_min=0,\n",
    "    train_transmissions_max=10,\n",
    "    \n",
    "    # Deployment environment parameters\n",
    "    deploy_attack_agents_min=20,\n",
    "    deploy_attack_agents_max=60,\n",
    "    deploy_legitimate_clients_min=100,\n",
    "    deploy_legitimate_clients_max=300,\n",
    "    deploy_servers_min=10,\n",
    "    deploy_servers_max=30,\n",
    "    deploy_transmissions_min=10,\n",
    "    deploy_transmissions_max=30,\n",
    "    \n",
    "    # Current symbolic program code\n",
    "    current_symbolic_program=\"\"\"\n",
    "    void ApplyAction(uint32_t action, std::map<Ipv4Address, SourceBehaviorStats>& sourceBehaviorMap) {\n",
    "        // Step 1: compute suspicious score based on rules\n",
    "\n",
    "        const double DECAY_RATE = 0.9;  // decay rate\n",
    "        std::vector<std::pair<Ipv4Address, double>> activeSourceRanking;\n",
    "\n",
    "        for (const auto& [addr, stats] : sourceBehaviorMap) {\n",
    "            if (stats.isActive) {\n",
    "                double dropRate = static_cast<double>(stats.totalDroppedPackets) / stats.totalTxPackets;\n",
    "                double suspiciousScore = (dropRate > 0.1) \n",
    "                    ? dropRate * 0.8 + stats.activeRatio \n",
    "                    : stats.activeRatio;\n",
    "                    \n",
    "                activeSourceRanking.push_back({addr, suspiciousScore});\n",
    "                \n",
    "                // update the suspicious score for active sources\n",
    "                auto it = SuspiciousList.find(addr);\n",
    "                if (it != SuspiciousList.end()) {\n",
    "                    it->second = suspiciousScore;  // update the score\n",
    "                }\n",
    "            } else {\n",
    "                // decay the suspicious score for inactive sources\n",
    "                auto it = SuspiciousList.find(addr);\n",
    "                if (it != SuspiciousList.end()) {\n",
    "                    it->second *= DECAY_RATE;  \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // sort by suspicious score\n",
    "        std::sort(activeSourceRanking.begin(), activeSourceRanking.end(),\n",
    "                [](const auto& a, const auto& b) { return a.second > b.second; });\n",
    "\n",
    "        // Step 2: symbolic actions\n",
    "        std::string actionDescription;  \n",
    "        switch (action) {\n",
    "            case 0: {\n",
    "                // observe\n",
    "                actionDescription = \"Observe (No action taken)\";\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            case 1: {\n",
    "                // add to Suspicious List\n",
    "                int activeCount = activeSourceRanking.size();\n",
    "                if (activeCount == 0) {\n",
    "                    actionDescription = \"Add to Suspicious List (No active sources to add)\";\n",
    "                    break;\n",
    "                }\n",
    "\n",
    "                int numToAdd = std::max(1, activeCount / 2);\n",
    "                int count = 0;\n",
    "\n",
    "                for (const auto& [addr, suspiciousScore] : activeSourceRanking) {\n",
    "                    if (count >= numToAdd) break;\n",
    "\n",
    "                    if (BlackList.find(addr) == BlackList.end() && \n",
    "                        SuspiciousList.find(addr) == SuspiciousList.end()) {\n",
    "                        if (suspiciousScore < 0.2){\n",
    "                            std::cout << \"\\n===== Push Failed due to low suspicious score (< 0.2): \" << addr << \" =====\" << std::endl;\n",
    "                            continue; \n",
    "                        }\n",
    "                        SuspiciousList.insert({addr, suspiciousScore});\n",
    "                        count++;\n",
    "                    }\n",
    "                }\n",
    "                actionDescription = \"Add to Suspicious List (\" + std::to_string(count) + \" sources added)\";\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            case 2: {\n",
    "                // remove from Suspicious List\n",
    "                if (SuspiciousList.empty()) {\n",
    "                    actionDescription = \"Remove from Suspicious List (List is empty)\";\n",
    "                    break;\n",
    "                }\n",
    "\n",
    "                std::vector<std::pair<Ipv4Address, double>> suspiciousRanking(SuspiciousList.begin(), SuspiciousList.end());\n",
    "                std::sort(suspiciousRanking.begin(), suspiciousRanking.end(),\n",
    "                        [](const auto& a, const auto& b) { return a.second < b.second; });\n",
    "\n",
    "                // get the address with the lowest suspicious score\n",
    "                Ipv4Address toRemove = suspiciousRanking.front().first;\n",
    "                double minSuspiciousScore = suspiciousRanking.front().second;\n",
    "\n",
    "                // set a threshold for removing from the list\n",
    "                const double suspiciousThreshold = 1.0;\n",
    "                if (minSuspiciousScore > suspiciousThreshold) {\n",
    "                    // refuse to remove\n",
    "                    std::ostringstream oss;\n",
    "                    oss << toRemove;  \n",
    "                    actionDescription = \"Failed to remove from Suspicious List (Address: \" + oss.str() + \", Score too high: \" + std::to_string(minSuspiciousScore) + \")\";\n",
    "                    testSuspiciousSuccess = 0;\n",
    "                    break;\n",
    "                }\n",
    "\n",
    "                // remove from Suspicious List\n",
    "                SuspiciousList.erase(toRemove);\n",
    "                testSuspiciousSuccess = 1;\n",
    "                std::ostringstream oss;\n",
    "                oss << toRemove;  \n",
    "                actionDescription = \"Remove from Suspicious List (Address: \" + oss.str() + \", Score: \" + std::to_string(minSuspiciousScore) + \")\";\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            case 3: {\n",
    "                // promote to blacklist\n",
    "                std::vector<Ipv4Address> toPromote;\n",
    "\n",
    "                for (const auto& [addr, suspiciousScore] : SuspiciousList) {\n",
    "                    auto& stats = sourceBehaviorMap[addr];\n",
    "                    double dropRate = static_cast<double>(stats.totalDroppedPackets) / stats.totalTxPackets;\n",
    "                    double timeDuration = stats.lastSeenTime - stats.firstSeenTime;\n",
    "                    double TIME_THRESHOLD = 2.0; \n",
    "\n",
    "                    bool condition1 = stats.isActive &&\n",
    "                                    timeDuration > TIME_THRESHOLD &&\n",
    "                                    stats.activeRatio > 0.99;\n",
    "\n",
    "                    bool condition2 = stats.isActive &&\n",
    "                                    timeDuration > TIME_THRESHOLD &&\n",
    "                                    dropRate > 0.6;\n",
    "\n",
    "                    if (condition1 || condition2) {\n",
    "                        toPromote.push_back(addr);\n",
    "                        promoteBlackSuccess = 1;\n",
    "                    } else {\n",
    "                        promoteBlackSuccess = 0;\n",
    "                    }\n",
    "                }\n",
    "\n",
    "                for (const auto& addr : toPromote) {\n",
    "                    BlackList.insert(addr);\n",
    "                    SuspiciousList.erase(addr);\n",
    "                }\n",
    "                \n",
    "                ApplicationContainer newContainer;\n",
    "                for (int k = 0; k < NUMBER_OF_BOTS; ++k) {\n",
    "                    Ptr<Node> node = botNodes.Get(k);\n",
    "\n",
    "                    // get Bot IP\n",
    "                    Ipv4Address botIp = botInterfaces.GetAddress(k);\n",
    "                    std::cout << \"[INFO] Checking bot \" << k << \" with IP: \" << botIp << std::endl;\n",
    "\n",
    "                    // Check if the bot is in the blacklist\n",
    "                    if (BlackList.find(botIp) != BlackList.end()) {\n",
    "                        std::cout << \"Blacklisted bot detected: \" << botIp << std::endl;\n",
    "\n",
    "                        // get OnOffApplication\n",
    "                        Ptr<Application> app = node->GetApplication(0);\n",
    "                        Ptr<OnOffApplication> onOffApp = DynamicCast<OnOffApplication>(app);\n",
    "\n",
    "                        if (onOffApp) {\n",
    "                            std::cout << \"Stopping attack from bot: \" << botIp << std::endl;\n",
    "                            \n",
    "                            // stop OnOffApplication\n",
    "                            newContainer.Add(onOffApp);\n",
    "                            newContainer.Stop(Seconds(Simulator::Now().GetSeconds() + 0.1));\n",
    "\n",
    "                            std::cout << \"Attack stopped for bot with IP \" << botIp << std::endl;\n",
    "                        } else {\n",
    "                            std::cout << \"Failed to retrieve OnOffApplication for bot: \" << botIp << std::endl;\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "\n",
    "\n",
    "\n",
    "                actionDescription = \"Promote to Blacklist (\" + std::to_string(toPromote.size()) + \" sources promoted)\";\n",
    "                break;\n",
    "            }\n",
    "\n",
    "            default: {\n",
    "                actionDescription = \"Invalid Action\";\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // Step 3: print\n",
    "        std::cout << \"\\n===== Action Taken: \" << actionDescription << \" =====\" << std::endl;\n",
    "\n",
    "        std::cout << \"\\n===== Current Suspicious List =====\" << std::endl;\n",
    "        for (const auto& [addr, score] : SuspiciousList) {\n",
    "            std::cout << \"Address: \" << addr \n",
    "                    << \", Suspicious Score: \" << score << std::endl;\n",
    "        }\n",
    "\n",
    "        std::cout << \"\\n===== Current Blacklist =====\" << std::endl;\n",
    "        for (const auto& addr : BlackList) {\n",
    "            std::cout << \"Address: \" << addr << std::endl;\n",
    "        }\n",
    "        std::cout << \"====================================\\n\" << std::endl;\n",
    "    }\n",
    "\n",
    "    \"\"\",\n",
    "    \n",
    "    # Performance metrics table\n",
    "    performance_metrics_table=\"\"\"| Attack Intensity (Bot Nodes) | 20    | 30    | 40    | 50    | 60    |\n",
    "                                |------------------------------|-------|-------|-------|-------|-------|\n",
    "                                | Network Uptime Rate (%)      | 68.63 | 50.98 | 35.29 | 29.41 | 20.69 |\n",
    "                                | Malicious Node Detection (%) | 100.0 | 100.0 | 100.0 | 98.00 | 85.00 |\n",
    "                                | False Blocking Rate (%)      | 5.50  | 18.00 | 32.50 | 45.00 | 59.25 |\"\"\",\n",
    "    \n",
    "    # Critical issues\n",
    "    issue_1=\"While malicious node detection remains robust, network uptime deteriorates rapidly\",\n",
    "    issue_2=\"False blocking rate escalates significantly with increased attack intensity\",\n",
    "    issue_3=\"The symbolic action framework fails to provide timely defensive responses under high-pressure conditions\",\n",
    "    issue_4=\"The suspicious list management becomes a critical bottleneck\"\n",
    "):\n",
    "    # Calculate increase percentages\n",
    "    attack_agents_increase = int(((deploy_attack_agents_max/train_attack_agents_max) - 1) * 100)\n",
    "    legitimate_clients_increase = int(((deploy_legitimate_clients_max/train_legitimate_clients_max) - 1) * 100)\n",
    "    servers_increase = int(((deploy_servers_max/train_servers_max) - 1) * 100) if train_servers_max > 0 else 200\n",
    "    transmissions_increase = int(((deploy_transmissions_max/train_transmissions_max) - 1) * 100) if train_transmissions_max > 0 else 200\n",
    "    \n",
    "    # Format the prompt with all parameters\n",
    "    formatted_prompt = prompt_template.format(\n",
    "        TRAIN_ATTACK_AGENTS_MIN=train_attack_agents_min,\n",
    "        TRAIN_ATTACK_AGENTS_MAX=train_attack_agents_max,\n",
    "        TRAIN_LEGITIMATE_CLIENTS_MIN=train_legitimate_clients_min,\n",
    "        TRAIN_LEGITIMATE_CLIENTS_MAX=train_legitimate_clients_max,\n",
    "        TRAIN_SERVERS_MIN=train_servers_min,\n",
    "        TRAIN_SERVERS_MAX=train_servers_max,\n",
    "        TRAIN_TRANSMISSIONS_MIN=train_transmissions_min,\n",
    "        TRAIN_TRANSMISSIONS_MAX=train_transmissions_max,\n",
    "        \n",
    "        DEPLOY_ATTACK_AGENTS_MIN=deploy_attack_agents_min,\n",
    "        DEPLOY_ATTACK_AGENTS_MAX=deploy_attack_agents_max,\n",
    "        DEPLOY_LEGITIMATE_CLIENTS_MIN=deploy_legitimate_clients_min,\n",
    "        DEPLOY_LEGITIMATE_CLIENTS_MAX=deploy_legitimate_clients_max,\n",
    "        DEPLOY_SERVERS_MIN=deploy_servers_min,\n",
    "        DEPLOY_SERVERS_MAX=deploy_servers_max,\n",
    "        DEPLOY_TRANSMISSIONS_MIN=deploy_transmissions_min,\n",
    "        DEPLOY_TRANSMISSIONS_MAX=deploy_transmissions_max,\n",
    "        \n",
    "        ATTACK_AGENTS_INCREASE_PERCENT=attack_agents_increase,\n",
    "        LEGITIMATE_CLIENTS_INCREASE_PERCENT=legitimate_clients_increase,\n",
    "        SERVERS_INCREASE_PERCENT=servers_increase,\n",
    "        TRANSMISSIONS_INCREASE_PERCENT=transmissions_increase,\n",
    "        \n",
    "        CURRENT_SYMBOLIC_PROGRAM=current_symbolic_program,\n",
    "        PERFORMANCE_METRICS_TABLE=performance_metrics_table,\n",
    "        \n",
    "        ISSUE_1=issue_1,\n",
    "        ISSUE_2=issue_2,\n",
    "        ISSUE_3=issue_3,\n",
    "        ISSUE_4=issue_4\n",
    "    )\n",
    "    \n",
    "    return formatted_prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a cybersecurity expert specializing in neural-symbolic defense systems for network intrusion detection. I need your assistance to adapt the symbolic component of our trained Transformer in reinforcement learning defense agent to enhance its performance in a new deployment environment.\n",
      "\n",
      "## BACKGROUND AND PROBLEM FORMULATION\n",
      "\n",
      "Our research involves a neural-symbolic defense agent for Network Intrusion Detection Systems (NIDS) focused on Distributed Denial of Service (DDoS) attacks. The agent architecture combines:\n",
      "1. A neural component (RL agent) that processes network observations and selects actions\n",
      "2. A symbolic component (rule-based program) that executes concrete defense operations based on the RL agent's action selection\n",
      "\n",
      "While the agent performs optimally in its training environment, we observe significant performance degradation when deploying it in larger-scale environments. Rather than retraining the neural component (which would require substantial data collection, training time, and safety verification), we aim to adapt only the symbolic program component.\n",
      "\n",
      "## ENVIRONMENT SPECIFICATIONS\n",
      "\n",
      "### Current Simulator: NS3\n",
      "\n",
      "### Training Environment Parameters:\n",
      "- Attack agents (botnet nodes): 5-10\n",
      "- Legitimate clients: 15-30 \n",
      "- Servers/workstations in victim LAN: 0-10\n",
      "- Legitimate transmissions: 0-10\n",
      "\n",
      "### Deployment Environment Parameters:\n",
      "- Attack agents (botnet nodes): 20-60 (500% increase)\n",
      "- Legitimate clients: 100-300 (900% increase)\n",
      "- Servers/workstations in victim LAN: 10-30 (200% increase)\n",
      "- Legitimate transmissions: 10-30 (200% increase)\n",
      "\n",
      "## CURRENT SYMBOLIC PROGRAM\n",
      "\n",
      "The neural component selects from four discrete actions {a₀, a₁, a₂, a₃}, with the following symbolic program implementation:\n",
      "\n",
      "```C++\n",
      "\n",
      "    void ApplyAction(uint32_t action, std::map<Ipv4Address, SourceBehaviorStats>& sourceBehaviorMap) {\n",
      "        // Step 1: compute suspicious score based on rules\n",
      "\n",
      "        const double DECAY_RATE = 0.9;  // decay rate\n",
      "        std::vector<std::pair<Ipv4Address, double>> activeSourceRanking;\n",
      "\n",
      "        for (const auto& [addr, stats] : sourceBehaviorMap) {\n",
      "            if (stats.isActive) {\n",
      "                double dropRate = static_cast<double>(stats.totalDroppedPackets) / stats.totalTxPackets;\n",
      "                double suspiciousScore = (dropRate > 0.1) \n",
      "                    ? dropRate * 0.8 + stats.activeRatio \n",
      "                    : stats.activeRatio;\n",
      "                    \n",
      "                activeSourceRanking.push_back({addr, suspiciousScore});\n",
      "                \n",
      "                // update the suspicious score for active sources\n",
      "                auto it = SuspiciousList.find(addr);\n",
      "                if (it != SuspiciousList.end()) {\n",
      "                    it->second = suspiciousScore;  // update the score\n",
      "                }\n",
      "            } else {\n",
      "                // decay the suspicious score for inactive sources\n",
      "                auto it = SuspiciousList.find(addr);\n",
      "                if (it != SuspiciousList.end()) {\n",
      "                    it->second *= DECAY_RATE;  \n",
      "                }\n",
      "            }\n",
      "        }\n",
      "\n",
      "        // sort by suspicious score\n",
      "        std::sort(activeSourceRanking.begin(), activeSourceRanking.end(),\n",
      "                [](const auto& a, const auto& b) { return a.second > b.second; });\n",
      "\n",
      "        // Step 2: symbolic actions\n",
      "        std::string actionDescription;  \n",
      "        switch (action) {\n",
      "            case 0: {\n",
      "                // observe\n",
      "                actionDescription = \"Observe (No action taken)\";\n",
      "                break;\n",
      "            }\n",
      "\n",
      "            case 1: {\n",
      "                // add to Suspicious List\n",
      "                int activeCount = activeSourceRanking.size();\n",
      "                if (activeCount == 0) {\n",
      "                    actionDescription = \"Add to Suspicious List (No active sources to add)\";\n",
      "                    break;\n",
      "                }\n",
      "\n",
      "                int numToAdd = std::max(1, activeCount / 2);\n",
      "                int count = 0;\n",
      "\n",
      "                for (const auto& [addr, suspiciousScore] : activeSourceRanking) {\n",
      "                    if (count >= numToAdd) break;\n",
      "\n",
      "                    if (BlackList.find(addr) == BlackList.end() && \n",
      "                        SuspiciousList.find(addr) == SuspiciousList.end()) {\n",
      "                        if (suspiciousScore < 0.2){\n",
      "                            std::cout << \"\n",
      "===== Push Failed due to low suspicious score (< 0.2): \" << addr << \" =====\" << std::endl;\n",
      "                            continue; \n",
      "                        }\n",
      "                        SuspiciousList.insert({addr, suspiciousScore});\n",
      "                        count++;\n",
      "                    }\n",
      "                }\n",
      "                actionDescription = \"Add to Suspicious List (\" + std::to_string(count) + \" sources added)\";\n",
      "                break;\n",
      "            }\n",
      "\n",
      "            case 2: {\n",
      "                // remove from Suspicious List\n",
      "                if (SuspiciousList.empty()) {\n",
      "                    actionDescription = \"Remove from Suspicious List (List is empty)\";\n",
      "                    break;\n",
      "                }\n",
      "\n",
      "                std::vector<std::pair<Ipv4Address, double>> suspiciousRanking(SuspiciousList.begin(), SuspiciousList.end());\n",
      "                std::sort(suspiciousRanking.begin(), suspiciousRanking.end(),\n",
      "                        [](const auto& a, const auto& b) { return a.second < b.second; });\n",
      "\n",
      "                // get the address with the lowest suspicious score\n",
      "                Ipv4Address toRemove = suspiciousRanking.front().first;\n",
      "                double minSuspiciousScore = suspiciousRanking.front().second;\n",
      "\n",
      "                // set a threshold for removing from the list\n",
      "                const double suspiciousThreshold = 1.0;\n",
      "                if (minSuspiciousScore > suspiciousThreshold) {\n",
      "                    // refuse to remove\n",
      "                    std::ostringstream oss;\n",
      "                    oss << toRemove;  \n",
      "                    actionDescription = \"Failed to remove from Suspicious List (Address: \" + oss.str() + \", Score too high: \" + std::to_string(minSuspiciousScore) + \")\";\n",
      "                    testSuspiciousSuccess = 0;\n",
      "                    break;\n",
      "                }\n",
      "\n",
      "                // remove from Suspicious List\n",
      "                SuspiciousList.erase(toRemove);\n",
      "                testSuspiciousSuccess = 1;\n",
      "                std::ostringstream oss;\n",
      "                oss << toRemove;  \n",
      "                actionDescription = \"Remove from Suspicious List (Address: \" + oss.str() + \", Score: \" + std::to_string(minSuspiciousScore) + \")\";\n",
      "                break;\n",
      "            }\n",
      "\n",
      "            case 3: {\n",
      "                // promote to blacklist\n",
      "                std::vector<Ipv4Address> toPromote;\n",
      "\n",
      "                for (const auto& [addr, suspiciousScore] : SuspiciousList) {\n",
      "                    auto& stats = sourceBehaviorMap[addr];\n",
      "                    double dropRate = static_cast<double>(stats.totalDroppedPackets) / stats.totalTxPackets;\n",
      "                    double timeDuration = stats.lastSeenTime - stats.firstSeenTime;\n",
      "                    double TIME_THRESHOLD = 2.0; \n",
      "\n",
      "                    bool condition1 = stats.isActive &&\n",
      "                                    timeDuration > TIME_THRESHOLD &&\n",
      "                                    stats.activeRatio > 0.99;\n",
      "\n",
      "                    bool condition2 = stats.isActive &&\n",
      "                                    timeDuration > TIME_THRESHOLD &&\n",
      "                                    dropRate > 0.6;\n",
      "\n",
      "                    if (condition1 || condition2) {\n",
      "                        toPromote.push_back(addr);\n",
      "                        promoteBlackSuccess = 1;\n",
      "                    } else {\n",
      "                        promoteBlackSuccess = 0;\n",
      "                    }\n",
      "                }\n",
      "\n",
      "                for (const auto& addr : toPromote) {\n",
      "                    BlackList.insert(addr);\n",
      "                    SuspiciousList.erase(addr);\n",
      "                }\n",
      "                \n",
      "                ApplicationContainer newContainer;\n",
      "                for (int k = 0; k < NUMBER_OF_BOTS; ++k) {\n",
      "                    Ptr<Node> node = botNodes.Get(k);\n",
      "\n",
      "                    // get Bot IP\n",
      "                    Ipv4Address botIp = botInterfaces.GetAddress(k);\n",
      "                    std::cout << \"[INFO] Checking bot \" << k << \" with IP: \" << botIp << std::endl;\n",
      "\n",
      "                    // Check if the bot is in the blacklist\n",
      "                    if (BlackList.find(botIp) != BlackList.end()) {\n",
      "                        std::cout << \"Blacklisted bot detected: \" << botIp << std::endl;\n",
      "\n",
      "                        // get OnOffApplication\n",
      "                        Ptr<Application> app = node->GetApplication(0);\n",
      "                        Ptr<OnOffApplication> onOffApp = DynamicCast<OnOffApplication>(app);\n",
      "\n",
      "                        if (onOffApp) {\n",
      "                            std::cout << \"Stopping attack from bot: \" << botIp << std::endl;\n",
      "                            \n",
      "                            // stop OnOffApplication\n",
      "                            newContainer.Add(onOffApp);\n",
      "                            newContainer.Stop(Seconds(Simulator::Now().GetSeconds() + 0.1));\n",
      "\n",
      "                            std::cout << \"Attack stopped for bot with IP \" << botIp << std::endl;\n",
      "                        } else {\n",
      "                            std::cout << \"Failed to retrieve OnOffApplication for bot: \" << botIp << std::endl;\n",
      "                        }\n",
      "                    }\n",
      "                }\n",
      "\n",
      "\n",
      "\n",
      "                actionDescription = \"Promote to Blacklist (\" + std::to_string(toPromote.size()) + \" sources promoted)\";\n",
      "                break;\n",
      "            }\n",
      "\n",
      "            default: {\n",
      "                actionDescription = \"Invalid Action\";\n",
      "                break;\n",
      "            }\n",
      "        }\n",
      "\n",
      "        // Step 3: print\n",
      "        std::cout << \"\n",
      "===== Action Taken: \" << actionDescription << \" =====\" << std::endl;\n",
      "\n",
      "        std::cout << \"\n",
      "===== Current Suspicious List =====\" << std::endl;\n",
      "        for (const auto& [addr, score] : SuspiciousList) {\n",
      "            std::cout << \"Address: \" << addr \n",
      "                    << \", Suspicious Score: \" << score << std::endl;\n",
      "        }\n",
      "\n",
      "        std::cout << \"\n",
      "===== Current Blacklist =====\" << std::endl;\n",
      "        for (const auto& addr : BlackList) {\n",
      "            std::cout << \"Address: \" << addr << std::endl;\n",
      "        }\n",
      "        std::cout << \"====================================\n",
      "\" << std::endl;\n",
      "    }\n",
      "\n",
      "    \n",
      "```\n",
      "\n",
      "## PERFORMANCE METRICS AND DEGRADATION\n",
      "\n",
      "We observe the followiC++rformance degradation as attack intensity increases in the deployment environment:\n",
      "\n",
      "| Attack Intensity (Bot Nodes) | 20    | 30    | 40    | 50    | 60    |\n",
      "                                |------------------------------|-------|-------|-------|-------|-------|\n",
      "                                | Network Uptime Rate (%)      | 68.63 | 50.98 | 35.29 | 29.41 | 20.69 |\n",
      "                                | Malicious Node Detection (%) | 100.0 | 100.0 | 100.0 | 98.00 | 85.00 |\n",
      "                                | False Blocking Rate (%)      | 5.50  | 18.00 | 32.50 | 45.00 | 59.25 |\n",
      "\n",
      "The critical issues identified:\n",
      "1. While malicious node detection remains robust, network uptime deteriorates rapidly\n",
      "2. False blocking rate escalates significantly with increased attack intensity\n",
      "3. The symbolic action framework fails to provide timely defensive responses under high-pressure conditions\n",
      "4. The suspicious list management becomes a critical bottleneck\n",
      "\n",
      "## YOUR TASK\n",
      "\n",
      "Please propose specific modifications to our symbolic program to enhance its performance in the larger-scale deployment environment. Your recommendations should:\n",
      "\n",
      "1. Maintain the overall interface with the neural component (four discrete actions)\n",
      "2. Adapt the symbolic program's parameters, thresholds, and internal logic to handle significantly larger numbers of legitimate and malicious nodes\n",
      "3. Address the identified bottlenecks in suspicious list management (especially for action a₂)\n",
      "4. Reduce false positive rates while maintaining effective defense capabilities\n",
      "5. Improve dynamic adjustment to varying attack intensities\n",
      "\n",
      "For each proposed modification, please:\n",
      "- Specify the exact code changes\n",
      "- Explain the theoretical justification\n",
      "- Discuss anticipated improvements in each performance metric\n",
      "- Address potential trade-offs or limitations\n",
      "\n",
      "Your guidance will directly inform our research on LLM-guided adaptation of symbolic programs for neural-symbolic cybersecurity agents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_prompt = format_prompt()\n",
    "print(final_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ns3ai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
